summary(ols_first_correct_lm)
summary(ols_first_correct_lmer)
ols_first_correct_lmer  <- lmer(M ~ X + (X|ID)                     , data = ds_L)
m_hat_correct_lmer      <- fitted(ols_first_correct_lmer)
ols_second_correct_lmer <- lmer(Y ~ X + m_hat_correct_lmer + (1|ID), data = ds_L)
summary(ols_first_correct_lm)
summary(ols_first_correct_lmer)
summary(ols_second_correct_lm)
summary(ols_second_correct_lmer)
source('~/GitHub/GuidesForMyself/IV-and-ATT/iv_analysis_first_blush.R', echo=TRUE)
ols_first_correct_lmer  <- lmer(M ~ X + (1|ID)                     , data = ds_L)
m_hat_correct_lmer      <- fitted(ols_first_correct_lmer)
ols_second_correct_lmer <- lmer(Y ~ X + m_hat_correct_lmer + (1|ID), data = ds_L)
summary(ols_second_correct_lm)
summary(ols_second_correct_lmer)
# ---- load-packages
library(ltm)
# ---- load-packages
install.packages("ltm")
# ---- load-packages
library(ltm)
library(psych)
install.packages("psych")
library(mirt)
install.packages("mirt")
install.packages(c("ltm", "mirt", "psych"))
source('~/.active-rstudio-document', echo=TRUE)
prtin("hello")
print("hello")
head(data(LSAT))
data(LSAT)
head(LSAT)
ds <- LSAT
install.packages("mvtnorm")
install.packages("mvtnorm")
library(mvtnorm)
install.packages("mvtnorm")
install.packages("mvtnorm")
# ---- load-packages
library(ltm)
library(psych)
library(mirt)
print("hello")
head(data(LSAT))
data(LSAT)
head(LSAT)
library(mvtnorm)
library(msm)
irtmodel <- tlm(LSAT ~ z1, IRT.param = TRUE)
irtmodel <- ltm(LSAT ~ z1, IRT.param = TRUE)
irtmodel
summary(irtmodel)
coef(irtmodel)
plot(irtmodel, type = "ICC")
plot(irtmodel, type = "ICC", items = 3)
plot(irtmodel, type = "ICC", items = c(2,3))
plot(irtmodel, type = "IIC")
plot(irtmodel, type = "IIC", items = 0)
plot(irtmodel, type = "IIC")
plot(irtmodel, type = "IIC")
plot(irtmodel, type = "IIC", items = 0) #Plots TEST information curve. This one is best at discriminating between those with a theta of -2 ish.
plot(irtmodel, type = "IIC")
factor.scores(irtmodel)
factor.scores(irtmodel)
factor.scores(irtmodel)
?factor.scores()
factor.scores(irtmodel, f = z1)
factor.scores(irtmodel, f = ds$z1)
head(ds)
#This one isn't working. Not sure why.
factor.scores(irtmodel)
source('G:/Users/Andrew/Documents/GitHub/GuidesForMyself/irt-demo.R', echo=TRUE)
person.fit(irtmodel)
item.fit(irtmodel)
tpm(data = ds, type = "latent.trait", IRT.param = TRUE)
threepl_model <- tpm(data = ds, type = "latent.trait", IRT.param = TRUE)
summary(threepl_model)
coef(threepl_model)
plot(threepl_model, type = "ICC")
plot(threepl_model, type = "IIC", items = 0)
factor.scores(threepl_model)
person.fit(threepl_model)
item.fit(threepl_model)
anova(irtmodel, threepl_model)
#Following example in:
# https://www.youtube.com/watch?v=VtWsyUCGfhg&t=16s
# ---- load-packages
library(ltm)
library(psych)
library(mirt)
library(mvtnorm)
library(msm)
# ---- load-data
ds <- LSAT
twople_model <- ltm(LSAT ~ z1, IRT.param = TRUE)
summary(irtmodel)
coef(irtmodel)
#Intepretation:
# Difficulty (b or theta in the 2pl model) is given in terms of z scores. So item 1 and 5 look extremely easy.
# Discrimination (a) values; we'd like to see them at or above 1.
plot(twople_model, type = "ICC") # Plots item characteristic curves; all items at once.
plot(twople_model, type = "ICC", items = 3)
plot(twople_model, type = "ICC", items = c(2,3))
plot(twople_model, type = "IIC", items = 0) # Plots TEST information curve. This one is best at discriminating between those with a theta of -2 ish.
plot(twople_model, type = "IIC")            # Note: scale for information is often not easy to explain/understand.
#This one isn't working. Not sure why.
factor.scores(twople_model)
person.fit(twople_model)
item.fit(twople_model)
#This one isn't working. Not sure why.
factor.scores(twopl_model, data = ds)
#This one isn't working. Not sure why.
factor.scores(twopl_model, x = ds)
#Following example in:
# https://www.youtube.com/watch?v=VtWsyUCGfhg&t=16s
# ---- load-packages
library(ltm)
library(psych)
library(mirt)
library(mvtnorm)
library(msm)
# ---- load-data
ds <- LSAT
twopl_model <- ltm(LSAT ~ z1, IRT.param = TRUE)
summary(irtmodel)
coef(irtmodel)
#Intepretation:
# Difficulty (b or theta in the 2pl model) is given in terms of z scores. So item 1 and 5 look extremely easy.
# Discrimination (a) values; we'd like to see them at or above 1.
plot(twopl_model, type = "ICC") # Plots item characteristic curves; all items at once.
plot(twopl_model, type = "ICC", items = 3)
plot(twopl_model, type = "ICC", items = c(2,3))
plot(twopl_model, type = "IIC", items = 0) # Plots TEST information curve. This one is best at discriminating between those with a theta of -2 ish.
plot(twopl_model, type = "IIC")            # Note: scale for information is often not easy to explain/understand.
#This one isn't working. Not sure why.
factor.scores(twopl_model, x = ds)
#This one isn't working. Not sure why.
factor.scores(f = twopl_model)
twopl_model
#This one isn't working. Not sure why.
factor.scores(f = twopl_model, resp.patterns = LSAT)
#This one isn't working. Not sure why.
factor.scores(twopl_model, resp.patterns = LSAT)
#This one isn't working. Not sure why.
factor.scores(twopl_model, resp.patterns = ds)
#This one isn't working. Not sure why.
factor.scores(twopl_model)
#This one isn't working. Not sure why.
onepl_model <- rasch(ds)
factor.scores(onepl_model)
factor.scores(f = onepl_model)
ncol(onepl_model)
onepl_model
str(onepl_model)
ncol(onepl_model)
q <- as.data.frame(onepl_model)
ncol(twopl_model)
ncol(as.data.frame(coef(twopl_model)))
q <- as.data.frame(as.data.frame(coef(twopl_model)))
q
factor.scores(f = onepl_model)
factor.scores(f = q)
factor.scores(f = as.data.frame(coef(twopl_model)))
install.packages(c("RcppArmadillo", "vegan"))
library(Rtools)
install.package("rtools")
install.packages("rtools")
install.packages("Rtools")
install.packages("installr")
# installing/loading the package:
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
library(installr)
# using the package:
# this will start the updating process of your R installation.  It will check for newer versions, and
# if one is available, will guide you through the decisions you'd need to make.
updateR()
install.packages("wfe")
library(Rtools)
install.packages("Rtools")
rm(list = ls())
# ---- load-packages ------------------------------------------------------------------------------------------------------------------------
library(ggplot2)
library(dplyr)
library(AER)
library(lavaan)
library(lme4)
library(wfe)
# ---- declare-globals ------------------------------------------------------------------------------------------------------------------------
mySeed <- 7866
simN   <- 5000
# ---- simulate-data ------------------------------------------------------------------------------------------------------------------------
set.seed(mySeed)
# Creating Sample Data
# X (binary) and Z (continuous), predictors of mediator M
X         <- rbinom(n=simN,size=1,prob=.5)
Z         <- rnorm(n=simN)
linpred_M <- -15 + 15*X + .5*Z*X
M         <- rbinom(n=simN,size=1,plogis(linpred_M))
#M         <- 0 + .5*X + .5*Z + rnorm(n=simN)*sqrt(1)
# Outcome variable Y, regressed onto X, Y, and Z
Y         <- 0 + 0*X + .5*M + .5*Z + rnorm(n=simN)*sqrt(1)
ds        <- data.frame(list(Y=Y,M=M,X=X,Z=Z))
# Creating fake longitudinal variable with id and frailty term
id            <- rep(c(1:1000), 5)
id            <- id[order(id)]
frailzy       <- round(rep(rnorm(n = (simN/5)), 5), 3)
frailzy       <- frailzy[order(frailzy)]
L_X           <- rbinom(n=simN,size=1,prob=.5)
L_linpred_M   <- -15 + 15*L_X + .5*frailzy*L_X
L_M           <- rbinom(n=simN,size=1,plogis(L_linpred_M))
L_Y           <- 0 + 0*L_X + 0.5*L_M + 0.5*frailzy + rnorm(n=simN)*sqrt(1)
ds_L          <- data.frame(list(ID = id, Y = L_Y, M=L_M, X=L_X, Z = frailzy))
# ---- analyze-data ------------------------------------------------------------------------------------------------------------------------
# Baseline analysese
summary(glm(M~X          , "binomial" , data = ds_L))  # Modeling M: Almost correctly specified
summary(glm(M~X + Z      , "binomial" , data = ds_L))  # Modeling M: Almost correctly specified
summary(glm(M~X + Z + X*Z, "binomial" , data = ds_L))  # Modeling M: Correctly specified
summary(lm(Y~M    , data = ds_L)) # Modeling Y: Almost Correctly Specified
summary(lm(Y~X+M+Z, data = ds_L)) # Modeling Y: Correctly Specified
# cor(ds[,c(4:1)])
# ggplot(ds,aes(x=M)) + geom_histogram() + facet_grid(~X)
# Linear Model: Almost correct
fit.ols <- lm(Y~X+M, data = ds_L)
summary(fit.ols)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X, data = ds_L)
M_hat     <- fitted(ols_first)
summary(ols_first)
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds_L)
summary(ols_second)
# coef(ols_second)
coef(ols_second)
coef(ols_first)
table(M_hat)
head(ds_L)
table(ds_L$M)
table(ds_L$X)
(6.983771e-15) + (5.023734e-01)
table(table(ds_L$Y))
table(ds_L$Y)
table(M_hat)
summary(fit.ols)
table(ds_L$X)
table(table(fit.ols))
table(table(M_hat))
table(M_hat)
table(ds_L$M)
table(X = ds_L$X, M = ds_L$M)
table(X = ds_L$X, M = ds_L$M, useNA = TRUE)
table(X = ds_L$X, M = ds_L$M, useNA = "ifany")
M_hat     <- round(fitted(ols_first), 4)
table(M_hat)
coef(ols_first)
roun(coef(ols_first), 3)
round(coef(ols_first), 3)
summary(ols_first)
round(coef(ols_first), 3)
table(M_hat)
table(X = ds_L$X, M = ds_L$M, useNA = "ifany")
table(ds_L$X)
1258+1270
table(M_hat)
round(coef(ols_first), 3)
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds_L)
summary(ols_second)
# TSLS: Using ivreg() function from AER package
# In this case: Get's same results
iv_res <- ivreg(Y ~ M | X, data = ds_L)
summary(iv_res)
# TSLS: with lmer (which can accomodate id values)
ols_first_mixed <- lmer(M ~ X + (1|ID), data = ds_L)
M_hat_mixed     <- round(fitted(ols_first   , data = ds_L), 3)
summary(ols_first_mixed)
round(coef(ols_first_mixed))
round(fitted(ols_first_mixed))
round(fitted(ols_first_mixed), 3)
round(M_hat_mixed)
table(round(M_hat_mixed))
table(round(M_hat_mixed), 3)
table(round(M_hat_mixed, 3))
summary(ols_first_mixed)
round(coef(ls_first_mixed))
# TSLS: with lmer (which can accomodate id values)
ols_first_mixed <- lmer(M ~ X + (1|ID), data = ds_L)
M_hat_mixed     <- round(fitted(ols_first   , data = ds_L), 3)
summary(ols_first_mixed)
round(coef(ls_first_mixed))
round(coef(ols_first_mixed))
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds_L)
summary(ols_second)
table(M_hat)
round(coef(ols_first), 3)
table(X = ds_L$X, M = ds_L$M, useNA = "ifany")
summary(ols_first)
# TSLS: Using ivreg() function from AER package
# In this case: Get's same results
iv_res <- ivreg(Y ~ M | X, data = ds_L)
summary(iv_res)
summary(ols_second)
# TSLS: with lmer (which can accomodate id values)
ols_first_mixed <- lmer(M ~ X + (1|ID), data = ds_L)
M_hat_mixed     <- round(fitted(ols_first   , data = ds_L), 3)
round(fitted(ols_first_mixed), 3)
head(round(fitted(ols_first_mixed), 3))
head(ds_L)
head(M_hat_mixed)
head(M_hat_mixed, 15)
table(round(M_hat_mixed, 3))
# Second: regress Y onto Predicted M values
ols_second_mixed <- lmer(Y ~ M_hat_mixed + (1|ID), data = ds_L)
summary(ols_second_mixed)
summary(iv_res)
head(ranef(ols_first_mixed))
head(ranef(ols_first_mixed), 15)
View(ranef(ols_first_mixed), 15)
View(as.data.frame(ranef(ols_first_mixed), 15))
colnames(ds_L)
table(ds_L$ID)
table(table(ds_L$ID))
vec <-c(1:5)
vec
rep(vec, 5)
table(round(M_hat_mixed, 3))
rep(vec, each = 5)
ds_L2 <-
ds_L %>%
dplyr::mutate(
random_id_effects == rep(ranef(ols_first_mixed))
)
ds_L2 <-
ds_L %>%
dplyr::mutate(
random_id_effects = rep(ranef(ols_first_mixed))
)
view(head(ds_L2))
View(head(ds_L2))
View((head(ds_L2))[[6]][[1]])
rep(ranef(ols_first_mixed, each = 5))
rep(vec, each = 5)
head(rep(ranef(ols_first_mixed, each = 5)))
as.data.frame(ranef(ols_first_mixed))
ds_ranef <- as.data.frame(ols_first_mixed)
ds_ranef <- as.data.frame(rane(ols_first_mixed))
ds_ranef <- as.data.frame(ranef(ols_first_mixed))
View(head(ds_rane, 40))
View(head(ds_ranef, 40))
colnames(ds_L)
colnames(ds_ranef)
ds_L2 <-
ds_L %>%
dplyr::left_join(
ds_ranef, by = c(ID == grpvar)
)
ds_L2 <-
ds_L %>%
dplyr::left_join(
ds_ranef, by = c("ID" == "grpvar")
)
head(ds_ranef$grpvar)
ds_L2 <-
ds_L %>%
dplyr::left_join(
ds_ranef, by = c("ID" == "grp")
)
head(ds_ranef$grp)
str(ds_ranef)
ds_ranef <- as.data.frame(ranef(ols_first_mixed)) %>% tibble::as_tibble()
View(head(ds_ranef, 40))
ds_L2 <-
ds_L %>%
dplyr::left_join(
ds_ranef, by = c(ID == grp)
)
ds_L2 <-
ds_L %>%
dplyr::left_join(
ds_ranef,
by = c("ID" == "grp")
)
str(ds_L)
str(ds_ranef)
ds_ranef <-
ranef(ols_first_mixed) %>%
tibble::as_tibble()
ds_ranef <-
ranef(ols_first_mixed) %>%
tibble::as_tibble() %>%
dplyr::mutate(
grouping_var = as.integer(grp)
)
str(ds_ranef)
table(grp = ds_ranef$grp, gpr_new = ds_ranef$grouping_var)
table(grp = ds_ranef$grp, gpr_new = ds_ranef$grouping_var)
table(paste(ds_ranef$grp, ds_ranef$grouping_var, ""))
table(table(paste(ds_ranef$grp, ds_ranef$grouping_var, "")))
head(unique(paste(ds_ranef$grp, ds_ranef$grouping_var, "")))
ds_ranef <-
ranef(ols_first_mixed) %>%
tibble::as_tibble() %>%
dplyr::mutate(
grouping_var = as.integer(as.character(grp))
)
table(table(paste(ds_ranef$grp, ds_ranef$grouping_var, "")))
head(unique(paste(ds_ranef$grp, ds_ranef$grouping_var, "")))
table(grp = ds_ranef$grp, gpr_new = ds_ranef$grouping_var)
head(unique(paste(ds_ranef$grp, ds_ranef$grouping_var, "")))
table(unique(paste(ds_ranef$grp, ds_ranef$grouping_var, "")))
str(ds_L)
str(ds_ranef)
ds_L2 <-
ds_L %>%
dplyr::left_join(
ds_ranef,
by = c("ID" == "grp")
)
ds_L2 <-
ds_L %>%
dplyr::left_join(
ds_ranef,
by = c("ID" == "grouping_var")
)
ds_L2 <-
ds_L %>%
dplyr::left_join(
ds_ranef,
by = c("ID" = "grouping_var")
)
View(head(ds_L2, 40))
ds_ranef <-
ranef(ols_first_mixed) %>%
tibble::as_tibble() %>%
dplyr::mutate(
grouping_var  = as.integer(as.character(grp)),
id_effect_var = condval,
) %>%
dplyr::select(grouping_var, id_effect_var)
ds_L2 <-
ds_L %>%
dplyr::left_join(
ds_ranef,
by = c("ID" = "grouping_var")
)
View(head(ds_L2, 40))
ds_L2 <-
ds_L %>%
dplyr::left_join(
ds_ranef,
by = c("ID" = "grouping_var")
) %>%
dplyr::mutate(
M_hat_mixed_b = M_hat_mixed,
M_hat_mixed_with_random_id = M_hat_mixed_b + id_effect_var
)
View(head(ds_L2, 40))
str(ds_L2)
# Second: regress Y onto Predicted M values
ols_second_mixed <- lmer(Y ~ M_hat_mixed + (1|ID), data = ds_L)
summary(ols_second_mixed)
ols_second_mixed <- lmer(Y ~ M_hat_mixed_b + (1|ID), data = ds_L2)
summary(ols_second_mixed)
# Second step 2: regress Y onto predicted M values plus the random individual effect
ols_second_mixed <- lmer(Y ~ M_hat_mixed_with_random_id + (1|ID), data = ds_L2)
summary(ols_second_mixed)
# Second step 2: regress Y onto predicted M values plus the random individual effect
ols_second_mixed <- lmer(Y ~ M_hat_mixed_with_random_id, data = ds_L2)
# Second step 2: regress Y onto predicted M values plus the random individual effect
ols_second_mixed <- lmer(Y ~ M_hat_mixed_with_random_id + (1|ID), data = ds_L2)
summary(ols_second_mixed)
summary(ols_second_mixed_b)
# Second step 2: regress Y onto predicted M values plus the random individual effect
ols_second_mixed_b <- lmer(Y ~ M_hat_mixed_with_random_id + (1|ID), data = ds_L2)
summary(ols_second_mixed_b)
summary(ols_second_mixed)
# Second: regress Y onto Predicted M values
ols_second_mixed <- lmer(Y ~ M_hat_mixed_b + (1|ID), data = ds_L2)
summary(ols_second_mixed)
summary(iv_res)
summary(ols_second_mixed)
summary(ols_second_mixed_b)
# If we just added the mixed effects into second stage
ols_second_mixed_b <- lmer(Y ~ M_hat_mixed + (1|ID), data = ds_L2)
summary(ols_second_mixed_b)
# Second step 2: regress Y onto predicted M values plus the random individual effect
ols_second_mixed_b <- lmer(Y ~ M_hat_mixed_with_random_id + (1|ID), data = ds_L2)
summary(ols_second_mixed_b)
# Second: regress Y onto Predicted M values
ols_second_mixed <- lmer(Y ~ M_hat_mixed_b + (1|ID), data = ds_L2)
summary(ols_second_mixed)
# Second step 2: regress Y onto predicted M values plus the random individual effect
ols_second_mixed_b <- lmer(Y ~ M_hat_mixed_with_random_id + (1|ID), data = ds_L2)
summary(ols_second_mixed_b)
# If we just added the mixed effects into second stage
ols_second_mixed_c <- lmer(Y ~ M_hat_mixed + (1|ID), data = ds_L2)
summary(ols_second_mixed_b)
# If we just added the mixed effects into second stage
ols_second_mixed_c <- lmer(Y ~ M_hat + (1|ID), data = ds_L2)
summary(ols_second_mixed_b)
summary(iv_res)
# Second: regress Y onto Predicted M values
ols_second_mixed <- lmer(Y ~ M_hat_mixed_b + (1|ID), data = ds_L2)
summary(ols_second_mixed)
# Second step 2: regress Y onto predicted M values plus the random individual effect
ols_second_mixed_b <- lmer(Y ~ M_hat_mixed_with_random_id + (1|ID), data = ds_L2)
summary(ols_second_mixed_b)
# If we just added the mixed effects into second stage
ols_second_mixed_c <- lmer(Y ~ M_hat + (1|ID), data = ds_L2)
summary(ols_second_mixed_b)
