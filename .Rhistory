summary(lm(Y~X+M+Z))
# cor(ds[,c(4:1)])
# ggplot(ds,aes(x=M)) + geom_histogram() + facet_grid(~X)
# Linear Model: Almost correct
fit.ols <- lm(Y~X+M)
summary(fit.ols)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X)
M_hat     <- fitted(ols_first)
summary(ols_first)
# TSLS: with lmer (which can accomodate id values)
ols_first <- lmer(M ~ X + (1|ID), data = dsL)
M_hat     <- fitted(ols_first, data = dsL)
summary(ols_first)
# TSLS: with lmer (which can accomodate id values)
ols_first <- lmer(M ~ X + (ID|1), data = dsL)
M_hat     <- fitted(ols_first, data = dsL)
rm(list = ls())
# ---- load-packages ------------------------------------------------------------------------------------------------------------------------
library(ggplot2)
library(dplyr)
library(AER)
library(lavaan)
library(lme4)
# ---- declare-globals ------------------------------------------------------------------------------------------------------------------------
mySeed <- 7866
simN   <- 5000
# ---- simulate-data ------------------------------------------------------------------------------------------------------------------------
set.seed(mySeed)
# Creating Sample Data
# X (binary) and Z (continuous), predictors of mediator M
X         <- rbinom(n=simN,size=1,prob=.5)
Z         <- rnorm(n=simN)
linpred_M <- -15 + 15*X + .5*Z*X
M         <- rbinom(n=simN,size=1,plogis(linpred_M))
#M         <- 0 + .5*X + .5*Z + rnorm(n=simN)*sqrt(1)
# Outcome variable Y, regressed onto X, Y, and Z
Y         <- 0 + 0*X + .5*M + .5*Z + rnorm(n=simN)*sqrt(1)
ds        <- data.frame(list(Y=Y,M=M,X=X,Z=Z))
# Creating fake longitudinal variable with id and frailty term
id            <- rep(c(1:1000), 5)
id            <- id[order(id)]
frailzy       <- round(rep(rnorm(n = (simN/5)), 5), 3)
frailzy       <- frailzy[order(frailzy)]
L_linpred_M   <- -15 + 15*X + .5*frailzy*X
L_M           <- rbinom(n=simN,size=1,plogis(linpred_M))
L_Y           <- 0 + 0*X + .5*L_M + .5*frailzy + rnorm(n=simN)*sqrt(1)
dsL           <- data.frame(list(ID = id, Y = L_Y, M=L_M, X=X, Z = frailzy))
# ---- analyze-data ------------------------------------------------------------------------------------------------------------------------
# Baseline analysese
# Modeling M: Almost correctly specified
summary(glm(M~X,"binomial"))
summary(glm(M~X + Z,"binomial"))
# Modeling M: Correctly specified
summary(glm(M~X + Z + X*Z,"binomial"))
# Modeling Y: Almost Correctly Specified
summary(lm(Y~M))
# Modeling Y: Correctly Specified
summary(lm(Y~X+M+Z))
# cor(ds[,c(4:1)])
# ggplot(ds,aes(x=M)) + geom_histogram() + facet_grid(~X)
# Linear Model: Almost correct
fit.ols <- lm(Y~X+M)
summary(fit.ols)
# Linear Model: Almost correct
fit.ols <- lm(Y~X+M, data = ds)
summary(fit.ols)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X, data = ds)
M_hat     <- fitted(ols_first)
summary(ols_first)
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds)
summary(ols_second)
# TSLS: with lmer (which can accomodate id values)
ols_first <- lmer(M ~ X + (ID|), data = dsL)
M_hat     <- fitted(ols_first, data = dsL)
# TSLS: with lmer (which can accomodate id values)
ols_first <- lmer(M ~ X + (1|ID), data = dsL)
M_hat     <- fitted(ols_first, data = dsL)
summary(ols_first)
?isSingular
# Second: regress Y onto Predicted M values
ols_second <- lmer(Y ~ M_hat + (1|ID), data = dsL)
summary(ols_second)
iv_res <- ivreg(Y ~ M | X + Z)
summary(iv_res)
source('~/GitHub/GuidesForMyself/IV-and-ATT/iv_analysis_first_blush.R', echo=TRUE)
source('~/GitHub/GuidesForMyself/IV-and-ATT/iv_analysis_first_blush.R', echo=TRUE)
# ---- analyze-data ------------------------------------------------------------------------------------------------------------------------
# Baseline analysese
# Modeling M: Almost correctly specified
summary(glm(M~X,"binomial"))
rm(list = ls())
# ---- load-packages ------------------------------------------------------------------------------------------------------------------------
library(ggplot2)
library(dplyr)
library(AER)
library(lavaan)
library(lme4)
# ---- declare-globals ------------------------------------------------------------------------------------------------------------------------
mySeed <- 7866
simN   <- 5000
# ---- simulate-data ------------------------------------------------------------------------------------------------------------------------
set.seed(mySeed)
# Creating fake longitudinal variable with id and frailty term
id            <- rep(c(1:1000), 5)
id            <- id[order(id)]
frailzy       <- round(rep(rnorm(n = (simN/5)), 5), 3)
frailzy       <- frailzy[order(frailzy)]
X             <- rbinom(n=simN,size=1,prob=.5)
L_linpred_M   <- -15 + 15*X + .5*frailzy*X
L_M           <- rbinom(n=simN,size=1,plogis(linpred_M))
L_X           <- rbinom(n=simN,size=1,prob=.5)
rm(list = ls())
# ---- load-packages ------------------------------------------------------------------------------------------------------------------------
library(ggplot2)
library(dplyr)
library(AER)
library(lavaan)
library(lme4)
# ---- declare-globals ------------------------------------------------------------------------------------------------------------------------
mySeed <- 7866
simN   <- 5000
# ---- simulate-data ------------------------------------------------------------------------------------------------------------------------
set.seed(mySeed)
# # Creating Sample Data
# # X (binary) and Z (continuous), predictors of mediator M
# X         <- rbinom(n=simN,size=1,prob=.5)
# Z         <- rnorm(n=simN)
#
# linpred_M <- -15 + 15*X + .5*Z*X
# M         <- rbinom(n=simN,size=1,plogis(linpred_M))
# #M         <- 0 + .5*X + .5*Z + rnorm(n=simN)*sqrt(1)
#
# # Outcome variable Y, regressed onto X, Y, and Z
# Y         <- 0 + 0*X + .5*M + .5*Z + rnorm(n=simN)*sqrt(1)
#
# ds        <- data.frame(list(Y=Y,M=M,X=X,Z=Z))
# Creating fake longitudinal variable with id and frailty term
id            <- rep(c(1:1000), 5)
id            <- id[order(id)]
frailzy       <- round(rep(rnorm(n = (simN/5)), 5), 3)
frailzy       <- frailzy[order(frailzy)]
L_X           <- rbinom(n=simN,size=1,prob=.5)
L_linpred_M   <- -15 + 15*L_X + .5*frailzy*L_X
L_M           <- rbinom(n=simN,size=1,plogis(L_linpred_M))
L_Y           <- 0 + 0*L_X + 0.5*L_M + 0.5*frailzy + rnorm(n=simN)*sqrt(1)
ds_L          <- data.frame(list(ID = id, Y = L_Y, M=L_M, X=L_X, Z = frailzy))
colnames(ds_L)
# ---- analyze-data ------------------------------------------------------------------------------------------------------------------------
# Baseline analysese
# Modeling M: Almost correctly specified
summary(glm(M~X     ,"binomial" , data = ds_L))
summary(glm(M~X + Z ,"binomial" , data = ds_L))
# ---- analyze-data ------------------------------------------------------------------------------------------------------------------------
# Baseline analysese
# Modeling M: Almost correctly specified
summary(glm(M~X     ,"binomial" , data = ds))
rm(list = ls())
# ---- load-packages ------------------------------------------------------------------------------------------------------------------------
library(ggplot2)
library(dplyr)
library(AER)
library(lavaan)
library(lme4)
# ---- declare-globals ------------------------------------------------------------------------------------------------------------------------
mySeed <- 7866
simN   <- 5000
# ---- simulate-data ------------------------------------------------------------------------------------------------------------------------
set.seed(mySeed)
# Creating Sample Data
# X (binary) and Z (continuous), predictors of mediator M
X         <- rbinom(n=simN,size=1,prob=.5)
Z         <- rnorm(n=simN)
linpred_M <- -15 + 15*X + .5*Z*X
M         <- rbinom(n=simN,size=1,plogis(linpred_M))
#M         <- 0 + .5*X + .5*Z + rnorm(n=simN)*sqrt(1)
# Outcome variable Y, regressed onto X, Y, and Z
Y         <- 0 + 0*X + .5*M + .5*Z + rnorm(n=simN)*sqrt(1)
ds        <- data.frame(list(Y=Y,M=M,X=X,Z=Z))
# Creating fake longitudinal variable with id and frailty term
id            <- rep(c(1:1000), 5)
id            <- id[order(id)]
frailzy       <- round(rep(rnorm(n = (simN/5)), 5), 3)
frailzy       <- frailzy[order(frailzy)]
L_X           <- rbinom(n=simN,size=1,prob=.5)
L_linpred_M   <- -15 + 15*L_X + .5*frailzy*L_X
L_M           <- rbinom(n=simN,size=1,plogis(L_linpred_M))
L_Y           <- 0 + 0*L_X + 0.5*L_M + 0.5*frailzy + rnorm(n=simN)*sqrt(1)
ds_L          <- data.frame(list(ID = id, Y = L_Y, M=L_M, X=L_X, Z = frailzy))
# ---- analyze-data ------------------------------------------------------------------------------------------------------------------------
# Baseline analysese
# Modeling M: Almost correctly specified
summary(glm(M~X     ,"binomial" , data = ds))
summary(glm(M~X + Z ,"binomial" , data = ds))
summary(glm(M~X + Z + X*Z, "binomial", data = ds_L))  # Modeling M: Correctly specified
# Modeling Y: Almost Correctly Specified
summary(lm(Y~M, data = ds_L))
summary(lm(Y~M    , data = ds_L)) # Modeling Y: Almost Correctly Specified
summary(lm(Y~X+M+Z, data = ds_L)) # Modeling Y: Correctly Specified
# Linear Model: Almost correct
fit.ols <- lm(Y~X+M, data = ds_L)
summary(fit.ols)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X, data = ds_L)
M_hat     <- fitted(ols_first)
summary(ols_first)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X, data = ds)
M_hat     <- fitted(ols_first)
summary(ols_first)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X, data = ds_L)
M_hat     <- fitted(ols_first)
summary(ols_first)
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds_L)
summary(ols_second)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X, data = ds)
M_hat     <- fitted(ols_first)
summary(ols_first)
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds)
summary(ols_second)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X, data = ds_L)
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds_L)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X, data = ds_L)
M_hat     <- fitted(ols_first)
summary(ols_first)
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds_L)
summary(ols_second)
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds_L)
summary(ols_second)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X, data = ds_L)
M_hat     <- fitted(ols_first)
summary(ols_first)
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds_L)
summary(ols_second)
# TSLS: Using ivreg() function from AER package
# In this case: Get's same results
iv_res <- ivreg(Y ~ M | X, data = ds)
summary(iv_res)
# TSLS: Using ivreg() function from AER package
# In this case: Get's same results
iv_res <- ivreg(Y ~ M | X, data = ds_L)
summary(iv_res)
summary(ols_second)
# Using sem() function from lavaan packages
# Instrumental Variables Approach
ivMod <- "
Y ~ intY*1 + b*M
M ~ intM*1 + a*X
#variances and residuals
Y ~~ start(.9)*Y
M ~~ start(1.25)*M
Y ~~ M
#Indirect effect
ab := a*b
"
fit <- sem(ivMod, fixed.x = FALSE, data=ds_L,)
summary(fit)
# Using sem() function from lavaan packages
# Instrumental Variables Approach
ivMod <-
"
Y ~ intY*1 + b*M
M ~ intM*1 + a*X
#variances and residuals
Y ~~ start(.9)*Y
M ~~ start(1.25)*M
Y ~~ M
#Indirect effect
ab := a*b
"
fit <- sem(ivMod, fixed.x = FALSE, data=ds)
summary(fit)
fit <- sem(ivMod, fixed.x = FALSE, data=ds_L)
# TSLS: with lmer (which can accomodate id values)
ols_first <- lmer(M ~ X + (1|ID), data = ds_L)
M_hat     <- fitted(ols_first   , data = ds_L)
summary(ols_first)
# TSLS: with lmer (which can accomodate id values)
ols_first_mixed <- lmer(M ~ X + (1|ID), data = ds_L)
M_hat_mixed     <- fitted(ols_first   , data = ds_L)
summary(ols_first_mixed)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X, data = ds_L)
M_hat     <- fitted(ols_first)
summary(ols_first)
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds_L)
summary(ols_second)
# Second: regress Y onto Predicted M values
ols_second_mixed <- lmer(Y ~ M_hat_mixed + (1|ID), data = ds_L)
summary(ols_second_mixed)
# Two-Stage Least-Squares regression: Piecemeal
# First: regress M onto X, get predicted M values
ols_first <- lm(M ~ X, data = ds_L)
M_hat     <- fitted(ols_first)
summary(ols_first)
# Second: regress Y onto Predicted M values
ols_second <- lm(Y ~ M_hat, data = ds_L)
summary(ols_second)
summary(ols_second_mixed)
# Compare correct (lm) to correct (lmer)
ols_first_correct_lm <- lm(M ~ X + X*Z, data = ds)
# Compare correct (lm) to correct (lmer)
ols_first_correct_lm  <- lm(M ~ X + X*Z                 , data = ds)
m_hat_correct_lm      <- fitted(ols_first_correct_lm)
ols_second_correct_lm <- lm(Y ~ X + m_hat_correct_lm + Z, data = ds)
# Compare correct (lm) to correct (lmer)
ols_first_correct_lm  <- lm(M ~ X + X*Z                 , data = ds)
m_hat_correct_lm      <- fitted(ols_first_correct_lm)
ols_second_correct_lm <- lm(Y ~ X + m_hat_correct_lm + Z, data = ds)
ols_first_correct_lmer  <- lmer(M ~ X + X*Z                   , data = ds_L)
m_hat_correct_lmer      <- fitted(ols_first_correct_lmer)
ols_second_correct_lmer <- lmer(Y ~ X + m_hat_correct_lmer + Z, data = ds_L)
ols_first_correct_lmer  <- lmer(M ~ X + (1|ID)                     , data = ds_L)
m_hat_correct_lmer      <- fitted(ols_first_correct_lmer)
ols_second_correct_lmer <- lmer(Y ~ X + m_hat_correct_lmer + (1|ID), data = ds_L)
summary(ols_first_correct_lm)
summary(ols_first_correct_lmer)
summary(ols_second_correct_lm)
summary(ols_second_correct_lmer)
ols_first_correct_lmer  <- lmer(M ~ X + (X|ID)                     , data = ds_L)
m_hat_correct_lmer      <- fitted(ols_first_correct_lmer)
ols_second_correct_lmer <- lmer(Y ~ X + m_hat_correct_lmer + (1|ID), data = ds_L)
ols_first_correct_lmer  <- lmer(M ~ X + (X|ID)                     , data = ds_L)
m_hat_correct_lmer      <- fitted(ols_first_correct_lmer)
ols_second_correct_lmer <- lmer(Y ~ X + m_hat_correct_lmer + (1|ID), data = ds_L)
summary(ols_first_correct_lm)
summary(ols_first_correct_lmer)
ols_first_correct_lmer  <- lmer(M ~ X + (X|ID)                     , data = ds_L)
m_hat_correct_lmer      <- fitted(ols_first_correct_lmer)
ols_second_correct_lmer <- lmer(Y ~ X + m_hat_correct_lmer + (1|ID), data = ds_L)
summary(ols_first_correct_lm)
summary(ols_first_correct_lmer)
summary(ols_second_correct_lm)
summary(ols_second_correct_lmer)
source('~/GitHub/GuidesForMyself/IV-and-ATT/iv_analysis_first_blush.R', echo=TRUE)
ols_first_correct_lmer  <- lmer(M ~ X + (1|ID)                     , data = ds_L)
m_hat_correct_lmer      <- fitted(ols_first_correct_lmer)
ols_second_correct_lmer <- lmer(Y ~ X + m_hat_correct_lmer + (1|ID), data = ds_L)
summary(ols_second_correct_lm)
summary(ols_second_correct_lmer)
# ---- load-packages
library(ltm)
# ---- load-packages
install.packages("ltm")
# ---- load-packages
library(ltm)
library(psych)
install.packages("psych")
library(mirt)
install.packages("mirt")
install.packages(c("ltm", "mirt", "psych"))
source('~/.active-rstudio-document', echo=TRUE)
prtin("hello")
print("hello")
head(data(LSAT))
data(LSAT)
head(LSAT)
ds <- LSAT
install.packages("mvtnorm")
install.packages("mvtnorm")
library(mvtnorm)
install.packages("mvtnorm")
install.packages("mvtnorm")
# ---- load-packages
library(ltm)
library(psych)
library(mirt)
print("hello")
head(data(LSAT))
data(LSAT)
head(LSAT)
library(mvtnorm)
library(msm)
irtmodel <- tlm(LSAT ~ z1, IRT.param = TRUE)
irtmodel <- ltm(LSAT ~ z1, IRT.param = TRUE)
irtmodel
summary(irtmodel)
coef(irtmodel)
plot(irtmodel, type = "ICC")
plot(irtmodel, type = "ICC", items = 3)
plot(irtmodel, type = "ICC", items = c(2,3))
plot(irtmodel, type = "IIC")
plot(irtmodel, type = "IIC", items = 0)
plot(irtmodel, type = "IIC")
plot(irtmodel, type = "IIC")
plot(irtmodel, type = "IIC", items = 0) #Plots TEST information curve. This one is best at discriminating between those with a theta of -2 ish.
plot(irtmodel, type = "IIC")
factor.scores(irtmodel)
factor.scores(irtmodel)
factor.scores(irtmodel)
?factor.scores()
factor.scores(irtmodel, f = z1)
factor.scores(irtmodel, f = ds$z1)
head(ds)
#This one isn't working. Not sure why.
factor.scores(irtmodel)
source('G:/Users/Andrew/Documents/GitHub/GuidesForMyself/irt-demo.R', echo=TRUE)
person.fit(irtmodel)
item.fit(irtmodel)
tpm(data = ds, type = "latent.trait", IRT.param = TRUE)
threepl_model <- tpm(data = ds, type = "latent.trait", IRT.param = TRUE)
summary(threepl_model)
coef(threepl_model)
plot(threepl_model, type = "ICC")
plot(threepl_model, type = "IIC", items = 0)
factor.scores(threepl_model)
person.fit(threepl_model)
item.fit(threepl_model)
anova(irtmodel, threepl_model)
#Following example in:
# https://www.youtube.com/watch?v=VtWsyUCGfhg&t=16s
# ---- load-packages
library(ltm)
library(psych)
library(mirt)
library(mvtnorm)
library(msm)
# ---- load-data
ds <- LSAT
twople_model <- ltm(LSAT ~ z1, IRT.param = TRUE)
summary(irtmodel)
coef(irtmodel)
#Intepretation:
# Difficulty (b or theta in the 2pl model) is given in terms of z scores. So item 1 and 5 look extremely easy.
# Discrimination (a) values; we'd like to see them at or above 1.
plot(twople_model, type = "ICC") # Plots item characteristic curves; all items at once.
plot(twople_model, type = "ICC", items = 3)
plot(twople_model, type = "ICC", items = c(2,3))
plot(twople_model, type = "IIC", items = 0) # Plots TEST information curve. This one is best at discriminating between those with a theta of -2 ish.
plot(twople_model, type = "IIC")            # Note: scale for information is often not easy to explain/understand.
#This one isn't working. Not sure why.
factor.scores(twople_model)
person.fit(twople_model)
item.fit(twople_model)
#This one isn't working. Not sure why.
factor.scores(twopl_model, data = ds)
#This one isn't working. Not sure why.
factor.scores(twopl_model, x = ds)
#Following example in:
# https://www.youtube.com/watch?v=VtWsyUCGfhg&t=16s
# ---- load-packages
library(ltm)
library(psych)
library(mirt)
library(mvtnorm)
library(msm)
# ---- load-data
ds <- LSAT
twopl_model <- ltm(LSAT ~ z1, IRT.param = TRUE)
summary(irtmodel)
coef(irtmodel)
#Intepretation:
# Difficulty (b or theta in the 2pl model) is given in terms of z scores. So item 1 and 5 look extremely easy.
# Discrimination (a) values; we'd like to see them at or above 1.
plot(twopl_model, type = "ICC") # Plots item characteristic curves; all items at once.
plot(twopl_model, type = "ICC", items = 3)
plot(twopl_model, type = "ICC", items = c(2,3))
plot(twopl_model, type = "IIC", items = 0) # Plots TEST information curve. This one is best at discriminating between those with a theta of -2 ish.
plot(twopl_model, type = "IIC")            # Note: scale for information is often not easy to explain/understand.
#This one isn't working. Not sure why.
factor.scores(twopl_model, x = ds)
#This one isn't working. Not sure why.
factor.scores(f = twopl_model)
twopl_model
#This one isn't working. Not sure why.
factor.scores(f = twopl_model, resp.patterns = LSAT)
#This one isn't working. Not sure why.
factor.scores(twopl_model, resp.patterns = LSAT)
#This one isn't working. Not sure why.
factor.scores(twopl_model, resp.patterns = ds)
#This one isn't working. Not sure why.
factor.scores(twopl_model)
#This one isn't working. Not sure why.
onepl_model <- rasch(ds)
factor.scores(onepl_model)
factor.scores(f = onepl_model)
ncol(onepl_model)
onepl_model
str(onepl_model)
ncol(onepl_model)
q <- as.data.frame(onepl_model)
ncol(twopl_model)
ncol(as.data.frame(coef(twopl_model)))
q <- as.data.frame(as.data.frame(coef(twopl_model)))
q
factor.scores(f = onepl_model)
factor.scores(f = q)
factor.scores(f = as.data.frame(coef(twopl_model)))
